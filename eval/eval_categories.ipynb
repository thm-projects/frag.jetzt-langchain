{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f4abd4-6016-45a6-9fd4-32b05d6f95bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "api_key=\"sk...\"\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\", api_key=api_key, max_retries=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a561dc0d-49fa-4867-9f4a-ad21b24144bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CategoryList(BaseModel):\n",
    "    \"\"\"All categories from the content\"\"\"\n",
    "\n",
    "    categories: list[str] = Field(description=\"The list containing all categories starting with uppercase, if useful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8b5fd3-c0de-4a70-b781-9905f4e970b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def transform(arr):\n",
    "    text = \"\"\n",
    "    for x in arr:\n",
    "        if type(x) == str:\n",
    "            text += x\n",
    "            continue\n",
    "        if type(x) == dict:\n",
    "            if 'attributes' in x:\n",
    "                if 'link' in x['attributes']:\n",
    "                    text += f\"[{x['insert']}]({x['attributes']['link']})\"\n",
    "                elif 'bold' in x['attributes']:\n",
    "                    text += f\"**{x['insert']}**\"\n",
    "                else:\n",
    "                    text += x['insert']\n",
    "            continue\n",
    "        print(x)\n",
    "    return text\n",
    "\n",
    "texts = []\n",
    "with open('test.csv', newline='\\n') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    first = True\n",
    "    for row in spamreader:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        arr = json.loads(row[0])\n",
    "        texts.append(transform(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c793721f-129a-4312-bb60-314eb10913c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 31.40297425002791\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "import time\n",
    "\n",
    "prompt = \"\"\"You are an expert in categorization and theme identification. Your task is to analyze each content section and generate **one concise, clear, and meaningful category** that best represents the core idea or main topic.  \n",
    "\n",
    "### Guidelines for the category:  \n",
    "1. It must accurately capture the essence of the content.  \n",
    "2. It should be precise, relevant, and unambiguous.  \n",
    "3. Only **one category** is allowed per section, regardless of length or complexity.  \n",
    "\n",
    "### Content Format:  \n",
    "The sections are presented as follows:  \n",
    "```\n",
    "<Content Number X>  \n",
    "Here goes the content.  \n",
    "</Content Number X>\n",
    "```  \n",
    "\n",
    "Focus on delivering **one-word clarity** while ensuring the category reflects the section's primary theme.\"\"\"\n",
    "\n",
    "def combine(text_list):\n",
    "    result = []\n",
    "    current_text = \"\"\n",
    "    for i, t in enumerate(text_list):\n",
    "        text = f'<Content Number {i+1}>\\n{t}\\n</Content Number {i+1}>'\n",
    "        if len(current_text) == 0:\n",
    "            current_text = text\n",
    "        elif len(current_text) + len(text) < 10000:\n",
    "            current_text = current_text + '\\n' + text\n",
    "        else:\n",
    "            result.append(current_text)\n",
    "            current_text = text\n",
    "    if len(current_text) > 0:\n",
    "        result.append(current_text)\n",
    "    return result\n",
    "\n",
    "async def run_openai(text_list):\n",
    "    model = chat_model.with_structured_output(CategoryList)\n",
    "    text_list_chunked = combine(text_list)\n",
    "    result = CategoryList(categories=[])\n",
    "    before = time.perf_counter()\n",
    "    for t in text_list_chunked:\n",
    "        temp = await model.ainvoke([\n",
    "            SystemMessage(prompt),\n",
    "            HumanMessage(t)\n",
    "        ])\n",
    "        result.categories.extend(temp.categories)\n",
    "    after = time.perf_counter()\n",
    "    print(len(text_list_chunked), after - before)\n",
    "    result.categories = list(set(result.categories))\n",
    "    return result\n",
    "\n",
    "result = await run_openai(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8401768-5f5a-4674-b926-12b786c3f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378 1289\n"
     ]
    }
   ],
   "source": [
    "print(len(result.categories), len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc739e9-76fd-4a95-9ac1-faa8131fcf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.900449345994275\n"
     ]
    }
   ],
   "source": [
    "prompt2 = \"\"\"You are a content analysis expert specializing in identifying relationships between concepts. Based on a provided list of categories, your task is to **combine only those keywords that are naturally and meaningfully combinable** into a single, concise term or phrase.  \n",
    "\n",
    "### Guidelines for combination:  \n",
    "1. Combine categories only if their meanings naturally complement or enhance one another.  \n",
    "2. Ensure the combined term is clear, relevant, and precise.  \n",
    "3. Do not force combinations; leave unrelated categories as they are.  \n",
    "4. Aim for brevity while maintaining accuracy and relevance.  \n",
    "\n",
    "### Input Format:  \n",
    "You will receive a list of categories in this format:  \n",
    "```\n",
    "Category 1  \n",
    "Category 2  \n",
    "Category 3  \n",
    "...  \n",
    "```  \n",
    "\n",
    "Analyze and refine the categories list accordingly.\"\"\"\n",
    "before = time.perf_counter()\n",
    "result2 = await chat_model.with_structured_output(CategoryList).ainvoke([\n",
    "    SystemMessage(prompt),\n",
    "    HumanMessage(\"\\n\".join(result.categories))\n",
    "])\n",
    "after = time.perf_counter()\n",
    "print(after - before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f48b5fd-1776-4df5-bdb6-b49dc0b7e9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n"
     ]
    }
   ],
   "source": [
    "keys = set(result.categories)\n",
    "print(len(result2.categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d42ef-0e94-4ff6-89e0-0bf58a49d832",
   "metadata": {},
   "source": [
    "# LLMLingua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d28f209-30e5-4844-a656-4af141b6bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (25722 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.999694033002015\n"
     ]
    }
   ],
   "source": [
    "from llmlingua import PromptCompressor\n",
    "import time\n",
    "import re\n",
    "llm_lingua = PromptCompressor(\n",
    "    model_name=\"microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank\",\n",
    "    use_llmlingua2=True, # Whether to use llmlingua-2\n",
    ")\n",
    "\n",
    "def prepare(data):\n",
    "    text = '.'.join(texts)\n",
    "    text = re.sub(r\"\\.(\\s*\\.)+\", \".\", text, count=0, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"\\?(\\s*\\?)+\", \"?\", text, count=0, flags=re.MULTILINE)\n",
    "    return re.sub(r\"!(\\s*!)+\", \"!\", text, count=0, flags=re.MULTILINE)\n",
    "    \n",
    "\n",
    "before = time.perf_counter()\n",
    "compressed = llm_lingua.compress_prompt(prepare(texts), target_token=10_000, force_tokens = ['?', '!', '.'])\n",
    "after = time.perf_counter()\n",
    "print(after - before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce6b9896-dfcc-4bcc-aa82-613ab76bc0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.305834759026766\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "prompt = \"\"\"You are an AI assistant tasked with analyzing a summarized text and extracting a list of general categories based on its content. Your role is to organize the text into high-level, non-contradictory categories that accurately represent the main topics or themes. These categories should be:  \n",
    "\n",
    "1. **General:** Broad enough to encompass subtopics within the text.  \n",
    "2. **Non-Contradictory:** Do not overlap in a way that creates logical conflicts.  \n",
    "3. **Relevant:** Directly related to the main ideas presented in the text.  \n",
    "\n",
    "Provide the categories as a clear, concise list without additional explanation unless requested.\"\"\"\n",
    "\n",
    "before = time.perf_counter()\n",
    "result3 = await chat_model.with_structured_output(CategoryList).ainvoke([\n",
    "    SystemMessage(prompt),\n",
    "    HumanMessage(compressed[\"compressed_prompt\"])\n",
    "])\n",
    "after = time.perf_counter()\n",
    "print(after - before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aad901d1-ba2b-4109-b46f-dfaff6397814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['General Chemistry',\n",
       " 'Biochemistry',\n",
       " 'Chemical Reactions',\n",
       " 'Data Analysis in Statistics',\n",
       " 'Statistical Methods',\n",
       " 'Experimental Design',\n",
       " 'Mathematical Concepts',\n",
       " 'Data Visualization in R',\n",
       " 'Biological Systems',\n",
       " 'Chemical Structures',\n",
       " 'Environmental Chemistry',\n",
       " 'Physical Chemistry',\n",
       " 'Analytical Chemistry',\n",
       " 'Laboratory Techniques',\n",
       " 'Chemistry Education',\n",
       " 'Statistical Inference',\n",
       " 'Sampling Techniques',\n",
       " 'Probability Theory',\n",
       " 'Chemical Equilibrium',\n",
       " 'Acid-Base Chemistry',\n",
       " 'Thermodynamics']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compressed[\"compressed_prompt\"]), len(result3.categories)\n",
    "#compressed[\"compressed_prompt\"]\n",
    "result3.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d46d6a64-2d84-49a2-9edf-983e548f7219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "\n",
    "class CategorySelect(BaseModel):\n",
    "    \"\"\"The selected category or null/None for the content\"\"\"\n",
    "\n",
    "    category: Optional[str] = Field(description=\"The selected category, if available\")\n",
    "\n",
    "\n",
    "prompt = SystemMessagePromptTemplate.from_template(\"\"\"You are an AI assistant tasked with determining if a piece of content belongs to any category from the following predefined list:\n",
    "\n",
    "{categories}\n",
    "\n",
    "Your role:\n",
    "1. **Match the Content:** Compare the content to each category and decide if it aligns with any of them.\n",
    "2. **Output the Category:** If the content fits a category, output the most appropriate category from the list.\n",
    "3. **Exclusion:** If the content does not fit any category, respond with nothing.\n",
    "\n",
    "Provide only the selected category or nothing as the output, ensuring precision and consistency in your decisions.\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "async def run_category_select(model, categories: list[str], text_list: list[str]):\n",
    "    shared = prompt.format(categories=\"\\n\".join(categories))\n",
    "    return await model.with_structured_output(CategorySelect).abatch(\n",
    "        [\n",
    "            [\n",
    "                shared,\n",
    "                HumanMessage(text)\n",
    "            ] for text in text_list\n",
    "        ]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4290870d-93b2-499f-b945-b4981168f8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "from more_itertools import chunked\n",
    "import time\n",
    "batched_results = []\n",
    "i = 0\n",
    "for text_sub in chunked(texts, 16):\n",
    "    print(i)\n",
    "    i += 1\n",
    "    batch = await run_category_select(chat_model, result2.categories, text_sub)\n",
    "    batched_results.extend(batch)\n",
    "    time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d369d9c-9cc4-4ab6-8e19-f58433f42097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acknowledgment',\n",
       " 'Adjustment',\n",
       " 'Audio',\n",
       " 'Beauty',\n",
       " 'Blood',\n",
       " 'Bonus',\n",
       " 'Calculation',\n",
       " 'Calculator',\n",
       " 'Chemische',\n",
       " 'Clarification',\n",
       " 'Comments',\n",
       " 'Communication',\n",
       " 'Comparison',\n",
       " 'Comparisons',\n",
       " 'Concern',\n",
       " 'Concerns',\n",
       " 'Confusion',\n",
       " 'Connectivity',\n",
       " 'Consultation',\n",
       " 'Correction',\n",
       " 'Dank',\n",
       " 'Danke',\n",
       " 'Data',\n",
       " 'Decision',\n",
       " 'Decrease',\n",
       " 'Definition',\n",
       " 'Delay',\n",
       " 'Demand',\n",
       " 'Diagramm',\n",
       " 'Difference',\n",
       " 'Discussion',\n",
       " 'Display',\n",
       " 'Document',\n",
       " 'Elemente',\n",
       " 'Elements',\n",
       " 'Energien',\n",
       " 'Environment',\n",
       " 'Error',\n",
       " 'Evaluation',\n",
       " 'Exam',\n",
       " 'Example',\n",
       " 'Exercise',\n",
       " 'Explanation',\n",
       " 'Farewell',\n",
       " 'Feedback',\n",
       " 'File',\n",
       " 'Formatting',\n",
       " 'Formulas',\n",
       " 'Fragen',\n",
       " 'Frustration',\n",
       " 'Geometry',\n",
       " 'Gleichgewicht',\n",
       " 'Gleichung',\n",
       " 'Graphics',\n",
       " 'Graphing',\n",
       " 'Gratitude',\n",
       " 'Greeting',\n",
       " 'Greetings',\n",
       " 'Health',\n",
       " 'Help',\n",
       " 'Homework',\n",
       " 'Humor',\n",
       " 'Hydration',\n",
       " 'IQ',\n",
       " 'Importance',\n",
       " 'Independence',\n",
       " 'Inequality',\n",
       " 'Information',\n",
       " 'Inquiry',\n",
       " 'Interpretation',\n",
       " 'Issue',\n",
       " 'Issues',\n",
       " 'Klausur',\n",
       " 'Lecture',\n",
       " 'Lectures',\n",
       " 'Link',\n",
       " 'Location',\n",
       " 'Media',\n",
       " 'Methodology',\n",
       " 'Monday',\n",
       " 'Negativität',\n",
       " 'Noise',\n",
       " None,\n",
       " 'None',\n",
       " 'Observation',\n",
       " 'Options',\n",
       " 'Overview',\n",
       " 'Percentage',\n",
       " 'Presentation',\n",
       " 'Properties',\n",
       " 'Query',\n",
       " 'Question',\n",
       " 'Questions',\n",
       " 'Quiz',\n",
       " 'Rauschmeldungen',\n",
       " 'Reaktion',\n",
       " 'Recommendation',\n",
       " 'Registration',\n",
       " 'Request',\n",
       " 'Response',\n",
       " 'Review',\n",
       " 'Seed',\n",
       " 'Slide',\n",
       " 'Slides',\n",
       " 'Smalltalk',\n",
       " 'Sound',\n",
       " 'Statistics',\n",
       " 'Stream',\n",
       " 'Streaming',\n",
       " 'Submission',\n",
       " 'Switching',\n",
       " 'Synchronization',\n",
       " 'Teaching',\n",
       " 'Temperature',\n",
       " 'Thanks',\n",
       " 'Theory',\n",
       " 'Toxicity',\n",
       " 'Troubleshooting',\n",
       " 'Umfrage',\n",
       " 'Unterricht',\n",
       " 'Update',\n",
       " 'Updates',\n",
       " 'Upload',\n",
       " 'Value',\n",
       " 'Verbindung',\n",
       " 'Videos',\n",
       " 'Visual',\n",
       " 'Volume',\n",
       " 'Vorlesung',\n",
       " 'Z-Score',\n",
       " 'none',\n",
       " 'null'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "api_key=\"sk...\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", api_key=api_key)\n",
    "\n",
    "with open('llmlingua.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "with open('normal-category.json', 'r', encoding='utf-8') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "classified = 0\n",
    "not_classified = 0\n",
    "to_embed = []\n",
    "labels = set()\n",
    "for i in range(len(texts)):\n",
    "    if data[i] is None:\n",
    "        not_classified += 1\n",
    "        labels.add(data2[i])\n",
    "        continue\n",
    "    classified += 1\n",
    "    to_embed.append(data[i])\n",
    "    to_embed.append(texts[i])\n",
    "\n",
    "all_lengths / not_classified\n",
    "labels\n",
    "#embedded_vecs = embeddings.embed_documents(to_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1809836f-5b62-4467-8171-54c15659fea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032 257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2816557796870045"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sum = 0\n",
    "for i in range(0, len(embedded_vecs), 2):\n",
    "    a = embedded_vecs[i]\n",
    "    b = embedded_vecs[i + 1]\n",
    "    length = len(a)\n",
    "    vec_a_val = sum(a[i] * a[i] for i in range(length)) ** 0.5\n",
    "    vec_b_val = sum(b[i] * b[i] for i in range(length)) ** 0.5\n",
    "    embedding_sum += sum(a[i] * b[i] for i in range(length)) / (vec_a_val * vec_b_val)\n",
    "print(classified, not_classified)\n",
    "\n",
    "# all categories, 0.28168227774694293 1032 class, 257 not class = 0.800620636\n",
    "# llmlingua, 0.2566732035409, 633 class, 656 not class = 0.491078355\n",
    "embedding_sum / classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42c25977-ba5a-4d95-856e-4d7240f7508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevantCategory(BaseModel):\n",
    "    \"\"\"Give information about a category\"\"\"\n",
    "    is_acceptable: bool = Field(description=\"Whether the category is acceptable and not overly specific\")\n",
    "    explanation: str = Field(description=\"An explanation for the acceptance\")\n",
    "\n",
    "prompt = \"Evaluate whether the following category is meaningful, general, and not overly specific. Respond with true or false and provide a brief explanation for your decision.\"\n",
    "\n",
    "cats = ['General Chemistry',\n",
    " 'Biochemistry',\n",
    " 'Chemical Reactions',\n",
    " 'Data Analysis in Statistics',\n",
    " 'Statistical Methods',\n",
    " 'Experimental Design',\n",
    " 'Mathematical Concepts',\n",
    " 'Data Visualization in R',\n",
    " 'Biological Systems',\n",
    " 'Chemical Structures',\n",
    " 'Environmental Chemistry',\n",
    " 'Physical Chemistry',\n",
    " 'Analytical Chemistry',\n",
    " 'Laboratory Techniques',\n",
    " 'Chemistry Education',\n",
    " 'Statistical Inference',\n",
    " 'Sampling Techniques',\n",
    " 'Probability Theory',\n",
    " 'Chemical Equilibrium',\n",
    " 'Acid-Base Chemistry',\n",
    " 'Thermodynamics']\n",
    "\n",
    "model = chat_model.with_structured_output(RelevantCategory)\n",
    "cat_result = []\n",
    "for category_sub in chunked(cats, 24):\n",
    "    cat_output = await model.abatch([\n",
    "        [\n",
    "            SystemMessage(prompt),\n",
    "            HumanMessage(category)\n",
    "        ] for category in category_sub\n",
    "    ])\n",
    "    cat_result.extend(cat_output)\n",
    "    time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32579b59-ccda-47da-9fbf-cb6b39413712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "for x in cat_result:\n",
    "    if x.is_acceptable:\n",
    "        pos += 1\n",
    "    else:\n",
    "        neg += 1\n",
    "\n",
    "print(pos / (pos + neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dbc169-0a2e-447b-860c-06e5bf4e3ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-train",
   "language": "python",
   "name": "conda-train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
